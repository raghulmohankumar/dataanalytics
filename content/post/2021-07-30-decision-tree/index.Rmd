---
title: Decision Tree
author: ''
date: '2021-07-30'
slug: decision-tree
categories: []
tags: []
---



<style>
body {
text-align: justify}
</style>

## Problem Statement:

The data is related with direct marketing campaigns of a Portuguese banking institution, which is rolling out term deposit for its customers. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be (or not) subscribed. The classification goal is to predict if the client will subscribe a term deposit (variable y).

## Data:

There are two datasets: 

      1) bank-full.csv with all examples, ordered by date (from May 2008 to November 2010).
      
      2) bank.csv with 10% of the examples (4521), randomly selected from bank-full.csv.
      
The smallest dataset is provided to test more computationally demanding machine learning algorithms (e.g. SVM).

Number of Instances: 45211 for bank-full.csv (4521 for bank.csv)
Number of Attributes: 16 + output attribute

## Data dictionary:

### Variables : Definition: Type and their categories

Each row represents characteristic of a single customer . Many categorical data has been coded to mask the data.

1 - age (numeric)

2 - job : type of job (categorical: “admin.”, “unknown”, “unemployed”, “management”, “housemaid”, “entrepreneur”, “student”, “blue-collar”, “self-employed”, “retired”,“technician”, “services”) 

3 - marital : marital status (categorical: “married”, “divorced”, “single”; note: “divorced” means divorced or widowed)

4 - education (categorical: “unknown”, “secondary”, “primary”, “tertiary”)

5 - default: has credit in default? (binary: “yes”, “no”)

6 - balance: average yearly balance, in euros (numeric)

7 - housing: has housing loan? (binary: “yes”,“no”)

8 - loan: has personal loan? (binary: “yes”,“no”)

Related with the last contact of the current campaign:

9 - contact: contact communication type (categorical: “unknown”, “telephone”, “cellular”)

10 - day: last contact day of the month (numeric))

Direct Marketing Campaign: Details and Phase I Tasks

11 - month: last contact month of year (categorical: “jan”, “feb”, “mar”, . . . , “nov”, “dec”)

12 - duration: last contact duration, in seconds (numeric)

other attributes: 13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)

14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted) 

15 - previous: number of contacts performed before this campaign and for this client (numeric)

16 - poutcome: outcome of the previous marketing campaign (categorical: “unknown”, “other”, “failure”, “success”)

Output variable (desired target):

17 - y - has the client subscribed a term deposit? (binary: “yes”,“no”)

## Load Packages
```{r warning=FALSE,echo=FALSE,message=FALSE}
library(dplyr)
library(ggplot2)
library(caret)
library(caTools)
library(rpart)
library(tidyr)
library(tidyverse)
library(dplyr)
library(tidymodels)
library(readr)
library(C50)
library(crosstable)
library(gmodels)
library(xtable)
library(Hmisc)
library(psych)
knitr::opts_chunk$set(echo = TRUE)
```

## Import Datasets : Bank data
```{r warning=FALSE,echo=FALSE,message=FALSE}
test=read.csv("bank.csv",sep = ";" ) 
train=read.csv("bank-full.csv", sep = ";") 
```

## Dataset Analysis
```{r  warning=FALSE,echo=FALSE,message=FALSE}
dim(train)
summary(train)
glimpse(train)
#describe(train)
statsBy(train,c("education","age"))
#stat.desc(train)
hist.data.frame(train)
prop.table(table(train$y))

```

## Building Decision Tree

We will use the C5.0 algorithm in the C50 package to train our decision tree model.Compared to the machine learning approaches we used previously, the C5.0 algorithm offers many more ways to tailor the model to a particular learning problem.

```{r echo=FALSE, message=FALSE, warning=FALSE}

train$y<-as.factor(train$y)
cmodel <- C5.0(train[-17],train$y)
cmodel
summary(cmodel)
cmodel_pred <- predict(cmodel, test)
CrossTable(test$y, cmodel_pred,
           prop.chisq = FALSE, 
           prop.c = FALSE, 
           prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))
```

## Results of train model

### Evaluation on training data (45211 cases):

The Errors output notes that the model correctly classified all but 3199 of the 45211 training instances for an error rate of 7.1%. A total of 1186 actual no values were incorrectly classified as no (false positives), while 2013 yes values were wrongly classified as no (false negatives).

Out of the 12433 test y application records, our model correctly predicted 3896 and 340 correctly, resulting in an accuracy of 93.69% and an error rate of 6.31%. This is a good performance for this kind of model although it´s necessary do more analysis and comparing with other classification models.

## Conclusion

The results show that the model are fitted to evaluate train data considering that errors is so low (7.1%) and the accuracy in the test set is 93.69%.

